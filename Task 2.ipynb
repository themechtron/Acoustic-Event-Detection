{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Task 2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPjGxaeIHVjcboeMd8s59cH"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jvFCmHEs4R7q","executionInfo":{"status":"ok","timestamp":1608211631922,"user_tz":-330,"elapsed":43432,"user":{"displayName":"Digumarthi Komal Emmanuel Raju","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJEmUm9wGww7E5bs1dNXrJyyguM6R8KBY1H6khPA=s64","userId":"05734232695022927052"}},"outputId":"5d858a18-fef2-4cf8-cf28-6bff71210e1b"},"source":["from google.colab import drive\r\n","drive.mount(\"/content/drive\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5qNgIau4rgq","executionInfo":{"status":"ok","timestamp":1608211677400,"user_tz":-330,"elapsed":1050,"user":{"displayName":"Digumarthi Komal Emmanuel Raju","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJEmUm9wGww7E5bs1dNXrJyyguM6R8KBY1H6khPA=s64","userId":"05734232695022927052"}},"outputId":"5f445724-540c-4586-87da-26b2514a9b9b"},"source":["%cd \"/content/drive/My Drive/College Work/Semester 7/EE698V/Project\""],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/College Work/Semester 7/EE698V/Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"liO9L9Ts4iHz","executionInfo":{"status":"ok","timestamp":1608211654289,"user_tz":-330,"elapsed":15956,"user":{"displayName":"Digumarthi Komal Emmanuel Raju","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJEmUm9wGww7E5bs1dNXrJyyguM6R8KBY1H6khPA=s64","userId":"05734232695022927052"}},"outputId":"fa63813d-a340-4a66-d6b4-8cdce4b69f33"},"source":["!pip install python-Levenshtein\r\n","!pip install librosa==0.8.0\r\n","# !pip install numpy==1.19\r\n","!pip install tensorflow"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting python-Levenshtein\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n","\r\u001b[K     |██████▊                         | 10kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 20kB 20.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 30kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 40kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-Levenshtein) (50.3.2)\n","Building wheels for collected packages: python-Levenshtein\n","  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144799 sha256=605fb43954006d59d7b75120c48abbd5e0099efa2a1f65d189aa017df36713e2\n","  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n","Successfully built python-Levenshtein\n","Installing collected packages: python-Levenshtein\n","Successfully installed python-Levenshtein-0.12.0\n","Collecting librosa==0.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/4d/c22d8ca74ca2c13cd4ac430fa353954886104321877b65fa871939e78591/librosa-0.8.0.tar.gz (183kB)\n","\u001b[K     |████████████████████████████████| 184kB 5.7MB/s \n","\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.8.0) (2.1.9)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.8.0) (1.18.5)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.8.0) (1.4.1)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.8.0) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.6/dist-packages (from librosa==0.8.0) (0.17.0)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.8.0) (4.4.2)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa==0.8.0) (0.2.2)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.8.0) (0.48.0)\n","Collecting soundfile>=0.9.0\n","  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n","Collecting pooch>=1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/b9/9876662636ba451d4406543047c0b45ca5b4e830f931308c8274dad1db43/pooch-1.3.0-py3-none-any.whl (51kB)\n","\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from resampy>=0.2.2->librosa==0.8.0) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.8.0) (50.3.2)\n","Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.8.0) (0.31.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa==0.8.0) (1.14.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa==0.8.0) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa==0.8.0) (20.7)\n","Collecting appdirs\n","  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.8.0) (2.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa==0.8.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa==0.8.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa==0.8.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa==0.8.0) (2020.12.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->pooch>=1.0->librosa==0.8.0) (2.4.7)\n","Building wheels for collected packages: librosa\n","  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for librosa: filename=librosa-0.8.0-cp36-none-any.whl size=201375 sha256=0406e45faca3a136ec1f99f933648c15adae8dff157d7bf61d2aa5aca91a3d25\n","  Stored in directory: /root/.cache/pip/wheels/ee/10/1e/382bb4369e189938d5c02e06d10c651817da8d485bfd1647c9\n","Successfully built librosa\n","Installing collected packages: soundfile, appdirs, pooch, librosa\n","  Found existing installation: librosa 0.6.3\n","    Uninstalling librosa-0.6.3:\n","      Successfully uninstalled librosa-0.6.3\n","Successfully installed appdirs-1.4.4 librosa-0.8.0 pooch-1.3.0 soundfile-0.10.3.post1\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n","Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n","Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.36.1)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.34.0)\n","Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (50.3.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.4.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NJFp92Aa4nMA","executionInfo":{"status":"ok","timestamp":1608211683435,"user_tz":-330,"elapsed":3676,"user":{"displayName":"Digumarthi Komal Emmanuel Raju","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJEmUm9wGww7E5bs1dNXrJyyguM6R8KBY1H6khPA=s64","userId":"05734232695022927052"}}},"source":["import librosa\r\n","import pickle\r\n","import librosa.display\r\n","import IPython.display as ipd\r\n","import utils\r\n","import glob\r\n","import os\r\n","import pandas as pd\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import os\r\n","import random\r\n","from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\r\n","from sklearn.metrics import confusion_matrix\r\n","import itertools\r\n","import tensorflow as tf\r\n","from tensorflow import keras\r\n","from tensorflow.keras import regularizers, initializers\r\n","from tensorflow.keras.models import Sequential\r\n","from tensorflow.keras.layers import Dense, Dropout, Activation\r\n","from tensorflow.keras.optimizers import Adam\r\n","from tqdm.notebook import tqdm\r\n","import numpy as np\r\n","from scipy.io.wavfile import write"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CXCzSGXk3F0M","executionInfo":{"status":"ok","timestamp":1608211689998,"user_tz":-330,"elapsed":3961,"user":{"displayName":"Digumarthi Komal Emmanuel Raju","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJEmUm9wGww7E5bs1dNXrJyyguM6R8KBY1H6khPA=s64","userId":"05734232695022927052"}},"outputId":"27eabd2d-24f9-44dc-9e60-c4567a376323"},"source":["model = keras.models.load_model('Save/Task_1/v3.model')\r\n","model.summary()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"sequential_17\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_96 (Dense)             (None, 256)               25856     \n","_________________________________________________________________\n","activation_91 (Activation)   (None, 256)               0         \n","_________________________________________________________________\n","dense_97 (Dense)             (None, 256)               65792     \n","_________________________________________________________________\n","activation_92 (Activation)   (None, 256)               0         \n","_________________________________________________________________\n","dense_98 (Dense)             (None, 128)               32896     \n","_________________________________________________________________\n","activation_93 (Activation)   (None, 128)               0         \n","_________________________________________________________________\n","dense_99 (Dense)             (None, 128)               16512     \n","_________________________________________________________________\n","activation_94 (Activation)   (None, 128)               0         \n","_________________________________________________________________\n","dense_100 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","activation_95 (Activation)   (None, 64)                0         \n","_________________________________________________________________\n","dropout_17 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_101 (Dense)            (None, 10)                650       \n","_________________________________________________________________\n","activation_96 (Activation)   (None, 10)                0         \n","=================================================================\n","Total params: 149,962\n","Trainable params: 149,962\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0xYvBD3v4uJl"},"source":["%cd \"/content/drive/My Drive/College Work/Semester 7/EE698V/Project\"\r\n","\r\n","def task_predictions(y_stft):\r\n","  # sound_clips = split_audio(y, w = 4000, h = 512, threshold_level = 0.1, tolerence=10)\r\n","  sound_clips = list(range(0, y_stft.shape[1], 86))\r\n","  if len(sound_clips)%2 != 0:\r\n","      sound_clips.append(y_stft.shape[1]-1)\r\n","  a = []\r\n","  for i in range(0, len(sound_clips)-1):\r\n","      a.append([sound_clips[i], sound_clips[i+1]])\r\n","  #print(a)\r\n","  ans = []\r\n","  final = \"\"\r\n","  for intvl in a:\r\n","      clip = y_stft[:, intvl[0]:intvl[1]]\r\n","      check = predictSound(clip, lb)\r\n","      if len(ans)==0 or ans[-1] != check:\r\n","          if(len(ans) == 0):\r\n","              final = check\r\n","          else:\r\n","            final = final + '-' + check\r\n","          ans.append(check)\r\n","  return final\r\n","\r\n","file_names = []\r\n","test_spectrogram = []\r\n","for i in range(0, 30):\r\n","    path = \"test_task2/feats/\"\r\n","    if(i<9):\r\n","      filename = \"a00\" + str(i+1) + \".npy\"\r\n","    else:\r\n","      filename = \"a0\" + str(i+1) + \".npy\"\r\n","    path = path + filename\r\n","    file_names.append(filename)\r\n","    with open(path, 'rb') as f:\r\n","      spectrum = np.load(f)\r\n","      test_spectrogram.append(spectrum)\r\n","\r\n","answers_task_2 = []\r\n","for i in range(0, 30):\r\n","    answers_task_2.append(task_predictions(test_spectrogram[i]))\r\n","answers_task_2\r\n","\r\n","final_array = np.vstack(([np.array(file_names), np.array(answers_task_2)]))\r\n","#print(final_array)\r\n","df = pd.DataFrame(final_array,).T\r\n","df.to_csv(\"est_task2.csv\")\r\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"whPRJhlY46OW"},"source":["%cd \"/content/drive/My Drive/College Work/Semester 7/EE698V/Project\"\r\n","def task_predictions(y_stft):\r\n","  # sound_clips = split_audio(y, w = 4000, h = 512, threshold_level = 0.1, tolerence=10)\r\n","  sound_clips = list(range(0, y_stft.shape[1], 86))\r\n","  if len(sound_clips)%2 != 0:\r\n","      sound_clips.append(y_stft.shape[1]-1)\r\n","  a = []\r\n","  for i in range(0, len(sound_clips)-1):\r\n","      a.append([sound_clips[i], sound_clips[i+1]])\r\n","  #print(a)\r\n","  ans = []\r\n","  final = \"\"\r\n","  for intvl in a:\r\n","      clip = y_stft[:, intvl[0]:intvl[1]]\r\n","      check = predictSound(clip, lb)\r\n","      if len(ans)==0 or ans[-1] != check:\r\n","          if(len(ans) == 0):\r\n","              final = check\r\n","          else:\r\n","            final = final + '-' + check\r\n","          ans.append(check)\r\n","  return final\r\n","\r\n","file_names = []\r\n","test_spectrogram = []\r\n","for i in range(0, 10):\r\n","    path = \"sample_test_task2/feats/\"\r\n","    if(i<9):\r\n","      filename = \"a0000\" + str(i+1) + \".npy\"\r\n","    else:\r\n","      filename = \"a000\" + str(i+1) + \".npy\"\r\n","    path = path + filename\r\n","    file_names.append(filename)\r\n","    with open(path, 'rb') as f:\r\n","      spectrum = np.load(f)\r\n","      test_spectrogram.append(spectrum)\r\n","\r\n","answers_sample_task_2 = []\r\n","for i in range(0, 10):\r\n","    answers_sample_task_2.append(task_predictions(test_spectrogram[i]))\r\n","\r\n","final_array1 = np.vstack(([np.array(file_names), np.array(answers_sample_task_2)]))\r\n","#print(final_array)\r\n","df1 = pd.DataFrame(final_array1).T\r\n","df1.head(), df.tail()"],"execution_count":null,"outputs":[]}]}